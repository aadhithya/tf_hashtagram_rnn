{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions, tags= utils.load_data('data/insta-hashtag-test1.json')\n",
    "\n",
    "\n",
    "c_word2idx, c_idx2word, c_vocab_size = utils.word_idx_mappings(captions)\n",
    "\n",
    "t_word2idx, t_idx2word, t_vocab_size = utils.word_idx_mappings(tags)\n",
    "\n",
    "\n",
    "captions, c_lengths = utils.text2idx(doc=captions,word2idx=c_word2idx)\n",
    "tags, t_lengths = utils.text2idx(tags,t_word2idx)\n",
    "\n",
    "captions = utils.pad_data(captions,c_lengths)\n",
    "#tags = utils.pad_data(captions,t_lengths)\n",
    "\n",
    "captions_tr,tags_tr,lengths_tr,captions_tst,tags_tst,lengths_tst = utils.generate_train_test_split(np.array(captions),np.array(tags),np.array(c_lengths))\n",
    "\n",
    "input_dims = len(captions_tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43842\n",
      "407\n"
     ]
    }
   ],
   "source": [
    "print(len(tags))\n",
    "print(len(captions_tr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerLSTM:\n",
    "    def __init__(self, name, c_word2idx, c_idx2word, c_vocab_size,\n",
    "                 t_word2idx, t_idx2word, t_vocab_size,input_dims,learning_rate=1e-2,\n",
    "                 batch_size=256,embedding_dims=64,num_hidden=128,num_layers=2,keep_prob=0.5, num_neg_samples=10,epochs=2):\n",
    "        self.name = name\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.num_hidden=num_hidden\n",
    "        self.num_layers=num_layers\n",
    "        self.keep_prob=keep_prob\n",
    "        self.input_dims=input_dims\n",
    "        self.epochs=epochs\n",
    "        self.num_sampled = num_neg_samples\n",
    "        self.word2idx={'captions':c_word2idx,\n",
    "                       'tags':t_word2idx\n",
    "                      }\n",
    "        self.idx2word={'captions':c_idx2word,\n",
    "                       'tags':t_idx2word\n",
    "                      }\n",
    "        self.vocab_size={'captions':c_vocab_size,\n",
    "                        'tags':t_vocab_size}\n",
    "        \n",
    "    def build(self):\n",
    "        with tf.variable_scope(self.name,reuse=tf.AUTO_REUSE):\n",
    "            self.inputs = tf.placeholder(dtype=tf.int32,shape=[None,self.input_dims], name='inputs')\n",
    "            self.targets = tf.placeholder(dtype=tf.int32, shape=[None,1], name='targets')\n",
    "            self.seq_lengths = tf.placeholder(dtype=tf.int32,shape=[None], name='inputs')\n",
    "            \n",
    "            \n",
    "            with tf.name_scope('Embeddings'):\n",
    "                self.embedding_matrix = tf.Variable(dtype=tf.float32,initial_value=tf.random_uniform([self.vocab_size['captions'],self.num_hidden],-1.0,1.0))\n",
    "                self.em_lookup = tf.nn.embedding_lookup(self.embedding_matrix,self.inputs)\n",
    "                \n",
    "            with tf.name_scope('LSTMs'):\n",
    "                def make_cell():\n",
    "                    cell = tf.contrib.rnn.LSTMCell(self.num_hidden)\n",
    "                    cell = tf.contrib.rnn.DropoutWrapper(cell,self.keep_prob)\n",
    "                    return cell\n",
    "                self.stacked_cells = [make_cell() for _ in range(self.num_layers)]\n",
    "                self.stacked_cells = tf.contrib.rnn.MultiRNNCell(self.stacked_cells)\n",
    "                \n",
    "                self.outputs, self.states = tf.nn.dynamic_rnn(self.stacked_cells,self.em_lookup,sequence_length=self.seq_lengths,dtype=tf.float32)\n",
    "                \n",
    "            with tf.name_scope('loss_accuracy'):\n",
    "                \n",
    "                self.Wl = tf.Variable(dtype=tf.float32, initial_value=tf.random_normal(shape=[self.vocab_size['tags'],self.num_hidden]), name='Wl')\n",
    "                self.bl = tf.Variable(dtype=tf.float32, initial_value=tf.random_normal(shape=[self.vocab_size['tags']]),name='bl')\n",
    "                                \n",
    "                self.train_loss = tf.reduce_mean(tf.nn.nce_loss(weights=self.Wl,biases=self.bl,labels=self.targets,\n",
    "                                                 inputs=self.outputs[:,-1,:],num_sampled=self.num_sampled,num_classes=self.vocab_size['tags']))\n",
    "                \n",
    "                self.logits = tf.matmul(self.outputs[:,-1,:],tf.transpose(self.Wl))+self.bl\n",
    "                \n",
    "                self.softmax = tf.nn.softmax(self.logits)\n",
    "                \n",
    "                self.eval_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits,labels=self.targets))\n",
    "                \n",
    "                self.correct_prediction = tf.equal(tf.argmax(self.targets,1), tf.argmax(self.logits, 1))\n",
    "                self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction,tf.float32))*100\n",
    "                self.opt_step = tf.train.AdamOptimizer(self.learning_rate).minimize(self.train_loss)\n",
    "                \n",
    "    \n",
    "    def train(self,tr_inputs,tr_targets,tr_lengths,val_inputs,val_targets,val_lengths):\n",
    "        \n",
    "        self.session = tf.Session()\n",
    "        sess = self.session\n",
    "        tr_losses=[]\n",
    "        tr_accs=[]\n",
    "        val_losses=[]\n",
    "        val_accs=[]\n",
    "        with sess.as_default():\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            for e in range(self.epochs):\n",
    "                step=0\n",
    "                print(f'EPOCH {e+1}:')\n",
    "                for batch_idx in utils.get_batch_idx(tr_inputs,self.batch_size):\n",
    "                    _ = sess.run([self.opt_step],feed_dict={self.inputs:tr_inputs[batch_idx],self.targets:tr_targets[batch_idx],self.seq_lengths:tr_lengths[batch_idx]})\n",
    "                    if step%4000 == 0:\n",
    "                        tr_loss,tr_acc=sess.run([self.eval_loss,self.accuracy],feed_dict={self.inputs:tr_inputs[batch_idx],\n",
    "                                                                                          self.targets:tr_targets[batch_idx],\n",
    "                                                                                          self.seq_lengths:tr_lengths[batch_idx]})\n",
    "                        \n",
    "                        val_loss,val_acc=sess.run([self.eval_loss,self.accuracy],feed_dict={self.inputs:val_inputs,self.targets:val_targets,self.seq_lengths:val_lengths})\n",
    "                        \n",
    "                        tr_losses+=[tr_loss]\n",
    "                        tr_accs+=[tr_acc]\n",
    "                        val_losses+=[val_loss]\n",
    "                        val_accs+=[val_acc]\n",
    "                        \n",
    "                        print(f'Iteration {step}:')\n",
    "                        print(f'TRAIN_LOSS:{tr_loss:.3f}, TRAIN_ACC:{tr_acc:.3f}')\n",
    "                        print(f'VAL_LOSS  :{val_loss:.3f}, VAL_ACC  :{val_acc:.3f}')\n",
    "\n",
    "                    step+=1\n",
    "            self.train_history={\n",
    "                'train_losses':tr_losses,\n",
    "                'train_accs':tr_accs,\n",
    "                'val_losses':val_losses,\n",
    "                'val_accs':val_accs\n",
    "            }\n",
    "                    \n",
    "    def predict(caption,num_tags):\n",
    "        \n",
    "        c_len = len(caption)\n",
    "        caption = [c_word2idx[word] for word in caption] + [0]*(self.input_dims-c_len)\n",
    "        \n",
    "        with self.session.as_default():\n",
    "            \n",
    "            smx = self.session.run(self.softmax,feed_dict={self.inputs:caption,self.seq_lengths:[c_len]})\n",
    "            \n",
    "            tag_ids = np.argsort(smx)[::-1]\n",
    "            tag_ids = tag_ids[:num_tags]\n",
    "            top_tags = [(t_idx2word[id],round(smx[id],3)) for id in tag_ids]\n",
    "            \n",
    "        return top_tags\n",
    "            \n",
    "                \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = MultiLayerLSTM('hashtagram',c_word2idx,c_idx2word,c_vocab_size,\n",
    "                     t_word2idx,t_idx2word,t_vocab_size,input_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-15bff1b72018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtags_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcaptions_tst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtags_tst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths_tst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-02be2896d873>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, tr_inputs, tr_targets, tr_lengths, val_inputs, val_targets, val_lengths)\u001b[0m\n\u001b[1;32m     83\u001b[0m                                                                                           self.seq_lengths:tr_lengths[batch_idx]})\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_lengths\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                         \u001b[0mtr_losses\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tum_ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tum_ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tum_ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tum_ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tum_ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tum_ml/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rnn.train(captions_tr,tags_tr,lengths_tr,captions_tst,tags_tst,lengths_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
